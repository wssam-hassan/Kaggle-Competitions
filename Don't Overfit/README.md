# Don't Overfit
###### This competition is a practice in Machine Learning Course provided by ITI on Reducing Overfitting. <br>
Reducing overfitting is the next logical step in facing overfitting in your model. Once again we have 20,000 rows of continuous variables, and a mere handful of training samples. Once again, we challenge you not to overfit. It's required to build a model without overfitting.

- Check this link for Kaggle Competition: https://www.kaggle.com/c/dont-overfit-ii
- Check this link for Kaggle Notebook: https://www.kaggle.com/wssamhassan/notebook91cb377708
<br>

## Repo Organization

    ├── data                      <- Data used in competition
    └── competition notebook
